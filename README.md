### KHAAdotPK (`khaa.pk`)

Welcome to **KHAAdotPK** (`khaa.pk`)! This collection of repositories is curated to provide a strong foundation for implementing various Machine Learning (`ML`) models using `C/C++` and `Rust`. The goal is to offer resources that not only facilitate understanding the core mechanics of these models but also empower developers to build robust and innovative machine learning solutions from scratch.

#### Getting Started

To get started, simply clone the desired repository into the `./lib` local directory of your project. Each repository is designed to be a standalone guide and resource, providing insights and code examples that reflect real-world applications of machine learning principles.

#### Available Guides

We have detailed guides that walk you through the implementation of key ML models, such as `Skip-gram` and `CBOW`. These guides are included as PDF documents within their respective repositories:

1. ~~[Skip-gram Implementation Guide (PDF)](./SkipGramImplementation.pdf): A comprehensive guide on implementing the Skip-gram model, a foundational algorithm in natural language processing, using `C/C++`~~.  
  - **Updated Skip-gram Implementation**: The model has been updated in a new repository and is constantly being improved. You can find the updated implementation here: [Skip-gram GitHub Repository](https://github.com/KHAAdotPK/skip-gram.git). ~~Work is being done to create a new, more detailed PDF guide~~.
  
**Additional Documentation**:
In the `DOCUMENTS` directory, we provide further insights into the key components of the Skip-gram implementation:
  - [README.md](https://github.com/KHAAdotPK/skip-gram/blob/main/DOCUMENTS/README.md): This document outlines how the Skip-gram model was implemented in C++, providing a general overview of the model's implementation structure.
  - [PROPOGATION.md](https://github.com/KHAAdotPK/skip-gram/blob/main/DOCUMENTS/PROPOGATION.md): Explains how the Skip-gram implementation in C++ propagates toward predicting context words, detailing the algorithm's mechanics.
  - [GradientDescent.md](https://github.com/KHAAdotPK/skip-gram/blob/main/DOCUMENTS/GradientDescent.md): As the name suggests, this document discusses gradient descent and how it was implemented in this implementation of Skip-gram model in C++.

2. ~~[CBOW Implementation Guide (PDF)](./StepByStepCBOW.pdf): A step-by-step guide for implementing the Continuous Bag of Words (CBOW) model in `C/C++`, offering insights into word embedding techniques and their applications~~.  
  - **Updated CBOW Implementation**: The model has been updated and is continuously being enhanced. Check out the latest version of the CBOW implementation here: [CBOW GitHub Repository](https://github.com/KHAAdotPK/CBOW.git). ~~A new PDF guide is under development~~.
<details>
<summary>Where we are heading...</summary>  
<!-- #### Where We Are Heading -->
At **KHAAdotPK**, the journey doesn't stop with Skip-gram and CBOW. We are currently expanding our focus to more advanced models, including the implementation of Transformer architectures, such as the Encoder-Decoder models, entirely from scratch. This ambitious effort aims to build a comprehensive library of fundamental ML models that are not only educational but also optimized for performance and scalability.

Our long-term vision is to provide tools and resources that enable businesses to harness the power of custom ML models, trained on in-house data, to drive insights and innovation. By continuing to develop these foundational models in `C/C++` and `Rust`, we aim to bridge the gap between high-level ML frameworks and the performance needs of commercial applications.
</details>

#### Contribute, Explore, and Innovate

Feel free to explore, experiment, and adapt the cloned repositories. The provided guides are there to enhance your understanding and application of these ML models. If you have any questions, suggestions, or would like to contribute, please don't hesitate to reach out. Your feedback and collaboration are invaluable as we strive to push the boundaries of what can be achieved with machine learning from the ground up.

Happy coding!
